"""
í…ìŠ¤íŠ¸ ìƒì„±ê¸° (Enhanced for Advanced Prompt System)

LangChain + ChromaDB RAG Systemê³¼ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì„ í™œìš©í•œ í•œêµ­ ë™í™” ìƒì„±
- êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ì ‘ê·¼ë²• (Role â†’ Objective â†’ Instructions â†’ Reasoning â†’ Output â†’ Examples)
- ì—°ë ¹ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸ (4-7ì„¸, 8-9ì„¸)
- ì²´ì¸ ì˜¤ë¸Œ ì†ŒíŠ¸ ì¶”ë¡  í†µí•©
- ì„±ëŠ¥ ì¶”ì  ë° ìµœì í™”
"""
from shared.utils.logging_utils import get_module_logger
import uuid
import time
from typing import Dict, List, Optional, Callable, Any
import json
import re
import asyncio

# LangChain imports
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

# Project imports
from .base_generator import BaseGenerator
from chatbot.data.vector_db.core import VectorDB
from chatbot.data.vector_db.query import get_similar_stories

# logging ì„¤ì •
logger = get_module_logger(__name__)

class TextGenerator(BaseGenerator):
    """
    ê°œì„ ëœ í…ìŠ¤íŠ¸ ìƒì„±ê¸°
    
    Features:
    - êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ (OpenAI ê¶Œì¥ í˜•ì‹)
    - ì—°ë ¹ë³„ ë§ì¶¤ ìƒì„± (4-7ì„¸, 8-9ì„¸)
    - ì²´ì¸ ì˜¤ë¸Œ ì†ŒíŠ¸ ì¶”ë¡  í†µí•©
    - ì„±ëŠ¥ ì¶”ì  ë° ë©”íŠ¸ë¦­
    - A/B í…ŒìŠ¤íŒ… ì§€ì› ì¤€ë¹„
    """
    
    def __init__(self,
                 openai_client = None,
                 vector_db_path: str = None,
                 collection_name: str = "fairy_tales",
                 prompts_file_path: str = "chatbot/data/prompts/chatbot_b_prompts.json",
                 max_retries: int = 3,
                 model_name: str = "gpt-4o",
                 temperature: float = 0.7,
                 enable_performance_tracking: bool = True,
                 model_kwargs: Dict[str, Any] = None):
        """
        Args:
            openai_client: OpenAI í´ë¼ì´ì–¸íŠ¸
            vector_db_path: ChromaDB ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ
            collection_name: ChromaDB ì»¬ë ‰ì…˜ ì´ë¦„
            prompts_file_path: ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            model_name: ì‚¬ìš©í•  LLM ëª¨ë¸ëª…
            temperature: ìƒì„± ì˜¨ë„
            enable_performance_tracking: ì„±ëŠ¥ ì¶”ì  í™œì„±í™”
            model_kwargs: LLM ëª¨ë¸ í‚¤ì›Œë“œ ì¸ìˆ˜ (ex: {"max_tokens": 1000})
        """
        super().__init__(max_retries=max_retries, timeout=180.0)
        
        self.openai_client = openai_client # OpenAI í´ë¼ì´ì–¸íŠ¸
        self.vector_db_path = vector_db_path # ChromaDB ê²½ë¡œ
        self.collection_name = collection_name # ChromaDB ì»¬ë ‰ì…˜ ì´ë¦„
        self.prompts_file_path = prompts_file_path # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ
        self.model_name = model_name # ì‚¬ìš©í•  LLM ëª¨ë¸ëª…
        self.temperature = temperature # ìƒì„± ì˜¨ë„
        self.enable_performance_tracking = enable_performance_tracking # ì„±ëŠ¥ ì¶”ì  í™œì„±í™”
        self.model_kwargs = model_kwargs or {} # LLM ëª¨ë¸ í‚¤ì›Œë“œ ì¸ìˆ˜ (ex: {"max_tokens": 1000})
        
        # Enhanced LangChain êµ¬ì„±
        self.vector_store = None
        self.retriever = None
        self.text_chains = {}  # ì—°ë ¹ë³„ ì²´ì¸
        self.prompts = None
        
        # ì„±ëŠ¥ ì¶”ì 
        self.performance_metrics = {
            "generation_times": [],
            "token_usage": [],
            "success_rate": 0,
            "error_count": 0,
            "age_group_usage": {}
            }
        
        # ì´ˆê¸°í™”
        self._initialize_components()
        
    def _initialize_components(self):
        """Enhanced LangChain êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”"""
        try:
            # 1. Enhanced Prompts ë¡œë“œ
            self._load_enhanced_prompts()
            
            # 2. ChromaDB ì´ˆê¸°í™”
            self._initialize_vector_db()
            
            # 3. Enhanced LangChain ì²´ì¸ ì„¤ì • (ì—°ë ¹ë³„)
            self._setup_enhanced_chains()
            
            logger.info("Enhanced TextGenerator ì´ˆê¸°í™” ì™„ë£Œ")
        
        except Exception as e:
            logger.error(f"Enhanced TextGenerator ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
            
    def _load_enhanced_prompts(self):
        """Enhanced í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ ë¡œë“œ"""
        try:
            with open(self.prompts_file_path, 'r', encoding='utf-8') as f:
                self.prompts = json.load(f)
            
            # ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ êµ¬ì¡° ê²€ì¦
            required_sections = ["enhanced_story_generation", "chain_of_thought_templates"]
            for section in required_sections:
                if section not in self.prompts:
                    logger.warning(f"í”„ë¡¬í”„íŠ¸ ì„¹ì…˜ '{section}' ì—†ìŒ. ê¸°ë³¸ê°’ ì‚¬ìš©")
                    
            logger.info(f"Enhanced í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {self.prompts_file_path}")
        
        except Exception as e:
            logger.error(f"Enhanced í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _initialize_vector_db(self):
        """ChromaDB ì´ˆê¸°í™”"""
        logger.info(f"VectorDB ì´ˆê¸°í™” ì‹œì‘ - ê²½ë¡œ: {self.vector_db_path}")
        
        if not self.vector_db_path:
            logger.warning("ChromaDB ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ. RAG ê¸°ëŠ¥ ë¹„í™œì„±í™”")
            return
        
        # ê²½ë¡œ ì¡´ì¬ í™•ì¸
        import os
        if not os.path.exists(self.vector_db_path):
            logger.error(f"VectorDB ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {self.vector_db_path}")
            self.vector_store = None
            return
            
        logger.info(f"VectorDB ê²½ë¡œ í™•ì¸ë¨: {self.vector_db_path}")
        
        try:
            self.vector_store = VectorDB(persist_directory=self.vector_db_path)
            logger.info(f"VectorDB ê°ì²´ ìƒì„± ì™„ë£Œ")
            
            # ì»¬ë ‰ì…˜ ì¡´ì¬ í™•ì¸
            try:
                collection = self.vector_store.get_collection(self.collection_name)
                logger.info(f"ChromaDB ì»¬ë ‰ì…˜ '{self.collection_name}' ì—°ê²° ì™„ë£Œ")
                
                # ì»¬ë ‰ì…˜ ë°ì´í„° ê°œìˆ˜ í™•ì¸
                try:
                    count = collection.count()
                    logger.info(f"ì»¬ë ‰ì…˜ '{self.collection_name}' ë°ì´í„° ê°œìˆ˜: {count}")
                except Exception as count_e:
                    logger.warning(f"ì»¬ë ‰ì…˜ ë°ì´í„° ê°œìˆ˜ í™•ì¸ ì‹¤íŒ¨: {count_e}")
                    
            except Exception as e:
                logger.warning(f"ì»¬ë ‰ì…˜ '{self.collection_name}' ì—°ê²° ì‹¤íŒ¨: {e}")
                logger.warning("RAG ê¸°ëŠ¥ì€ ì‚¬ìš©í•  ìˆ˜ ì—†ì§€ë§Œ ê¸°ë³¸ ìƒì„±ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        
        except Exception as e:
            logger.error(f"ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.vector_store = None
            logger.warning("VectorDB ì—†ì´ ê¸°ë³¸ ìƒì„± ëª¨ë“œë¡œ ì§„í–‰")
    
    def _setup_enhanced_chains(self):
        """Enhanced LangChain ì²´ì¸ ì„¤ì • (ì—°ë ¹ë³„)"""
        try:
            # ì—°ë ¹ë³„ ì²´ì¸ ìƒì„±
            age_groups = ["age_4_7", "age_8_9"]
            
            for age_group in age_groups:
                self._create_age_specific_chain(age_group)
            
            logger.info("Enhanced LangChain ì²´ì¸ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"Enhanced LangChain ì²´ì¸ ì„¤ì • ì‹¤íŒ¨: {e}")
            raise
    
    def _create_age_specific_chain(self, age_group: str):
        """ì—°ë ¹ë³„ íŠ¹í™” ì²´ì¸ ìƒì„±"""
        try:
            # Enhanced í”„ë¡¬í”„íŠ¸ êµ¬ì¡°ì—ì„œ ì—°ë ¹ë³„ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
            enhanced_prompts = self.prompts.get("enhanced_story_generation", {})
            age_config = enhanced_prompts.get(age_group, {})
            structured_prompt = age_config.get("structured_prompt", {})
            
            # êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            role = structured_prompt.get("role", "ì „ë¬¸ ë™í™” ì‘ê°€ë¡œì„œ")
            objective = structured_prompt.get("objective", "ëª°ì…ê° ìˆëŠ” ë™í™”ë¥¼ ì œì‘í•´ì£¼ì„¸ìš”.")
            instructions = structured_prompt.get("instructions", [])
            reasoning_steps = structured_prompt.get("reasoning_steps", [])
            
            # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
            system_template = self._build_structured_prompt(
                role=role,
                objective=objective,
                instructions=instructions,
                reasoning_steps=reasoning_steps,
                age_group=age_group
            )
            
            prompt_template = ChatPromptTemplate.from_template(system_template)
            
            # LLM ëª¨ë¸ ì„¤ì •
            llm = ChatOpenAI(
                temperature=self.temperature,
                model=self.model_name,
                api_key=self.openai_client.api_key if self.openai_client else None
            )
            
            # ì²´ì¸ êµ¬ì„±
            self.text_chains[age_group] = prompt_template | llm | StrOutputParser()
            
            logger.info(f"ì—°ë ¹ë³„ ì²´ì¸ ìƒì„± ì™„ë£Œ: {age_group}")
            
        except Exception as e:
            logger.error(f"ì—°ë ¹ë³„ ì²´ì¸ ìƒì„± ì‹¤íŒ¨ ({age_group}): {e}")
            raise
    
    def _build_structured_prompt(self, role: str, objective: str, 
                                instructions: List[str], reasoning_steps: List[str],
                                age_group: str) -> str:
        """êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± (OpenAI ê¶Œì¥ í˜•ì‹)"""
        
        # Chain-of-Thought ì¶”ë¡  ë‹¨ê³„ í†µí•©
        cot_templates = self.prompts.get("chain_of_thought_templates", {})
        # reasoning_template = cot_templates.get("story_development_reasoning", {}) # í˜„ì¬ ë¯¸ì‚¬ìš©
        
        prompt_parts = [
            f"## ROLE\n{role}",
            f"\n## OBJECTIVE\n{objective}",
            "\n## INSTRUCTIONS"
        ]
        
        # ì§€ì‹œì‚¬í•­ ì¶”ê°€
        for i, instruction in enumerate(instructions, 1):
            prompt_parts.append(f"{i}. {instruction}")
        
        # ì¶”ë¡  ë‹¨ê³„ ì¶”ê°€ (Chain-of-Thought)
        prompt_parts.append("\n## REASONING PROCESS")
        prompt_parts.append("ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆœì„œëŒ€ë¡œ ìˆ˜í–‰í•˜ì„¸ìš”:")
        
        for step in reasoning_steps:
            prompt_parts.append(f"- {step}")
            
        # ì¶œë ¥ í˜•ì‹ ì§€ì •
        # JSON ì˜ˆì‹œ ë¶€ë¶„ì„ ì¼ë°˜ ì—¬ëŸ¬ ì¤„ ë¬¸ìì—´ë¡œ ë³€ê²½í•˜ê³ , ë‚´ë¶€ ì¤‘ê´„í˜¸ëŠ” ì´ì¤‘ìœ¼ë¡œ ì´ìŠ¤ì¼€ì´í”„.
        output_format_json_example = """    
```json
{{
  \"title\": \"ë™í™” ì œëª©\",
  \"chapters\": [
    {{
      \"chapter_number\": 1,
      \"chapter_title\": \"ì±•í„° ì œëª©\",
      \"chapter_content\": \"ì±•í„° ë‚´ìš©\",
      \"educational_point\": \"êµìœ¡ì  í¬ì¸íŠ¸\",
      \"interaction_question\": \"ìƒí˜¸ì‘ìš© ì§ˆë¬¸\"
    }}
  ],
  \"reasoning_process\": \"ì¶”ë¡  ê³¼ì • ì„¤ëª…\"
}}
```"""

        prompt_parts.extend([
            "\n## OUTPUT FORMAT",
            "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:",
            output_format_json_example,
            "\n## INPUT DATA",
            "ë™í™” ì •ë³´: {story_outline}",
            "ì°¸ê³  ìŠ¤í† ë¦¬: {reference_stories}",
            "ì•„ì´ ì •ë³´: {child_info}"
        ])
        
        return "\n".join(prompt_parts)
    
    def _determine_age_group(self, target_age: int) -> str:
        """ì—°ë ¹ëŒ€ì— ë”°ë¥¸ ì²´ì¸ ì„ íƒ"""
        if 4 <= target_age <= 7:
            return "age_4_7"
        elif 8 <= target_age <= 9:
            return "age_8_9"
        else:
            # ê¸°ë³¸ê°’
            return "age_4_7" if target_age < 8 else "age_8_9"

    async def generate(self,
                       input_data: Dict[str, Any],
                       progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """
        Enhanced ë™í™” í…ìŠ¤íŠ¸ ìƒì„±
        
        Args:
            input_data: {
                "theme": "ë™í™” ì£¼ì œ",
                "child_name": "ì•„ì´ ì´ë¦„", 
                "age_group": "ì—°ë ¹ëŒ€",
                "target_age": êµ¬ì²´ì  ë‚˜ì´,
                "interests": ["ê´€ì‹¬ì‚¬1", "ê´€ì‹¬ì‚¬2"...],
                "plot_summary": "ìš”ì•½ ì¤„ê±°ë¦¬",
                "educational_value": "êµìœ¡ì  ê°€ì¹˜"
            }
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°±
        
        Returns:
            Enhanced ìŠ¤í† ë¦¬ ë°ì´í„° with ì„±ëŠ¥ ë©”íŠ¸ë¦­
        """
        start_time = time.time()
        story_id = str(uuid.uuid4())
        self.current_task_id = story_id
        
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ í™•ì¸
            logger.info(f"ğŸ”¥ OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ: {self.openai_client is not None}")
            logger.info(f"ğŸ”¥ VectorDB ìƒíƒœ: {self.vector_store is not None}")
            logger.info(f"ğŸ”¥ Text chains ìƒíƒœ: {len(self.text_chains) if self.text_chains else 0}ê°œ")
            
            # ì—°ë ¹ëŒ€ ê²°ì •
            target_age = input_data.get("target_age", input_data.get("age_group", 7))
            age_group_key = self._determine_age_group(target_age)
            logger.info(f"ğŸ”¥ ê²°ì •ëœ ì—°ë ¹ëŒ€: {target_age} -> {age_group_key}")
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            if progress_callback:
                await progress_callback({
                    "step": "enhanced_text_generation",
                    "status": "starting",
                    "story_id": story_id,
                    "age_group": age_group_key,
                    "prompt_version": "2.0_enhanced"
                })
            
            # 1. RAG ê²€ìƒ‰ ìˆ˜í–‰ (Enhanced)
            reference_stories = await self._retrieve_similar_stories(input_data)
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            if progress_callback:
                await progress_callback({
                    "step": "rag_retrieval",
                    "status": "completed",
                    "retrieved_count": len(reference_stories)
                })
            
            # 2. Enhanced í”„ë¡¬í”„íŠ¸ ë°ì´í„° ì¤€ë¹„
            prompt_data = self._prepare_enhanced_prompt_data(
                input_data, reference_stories, age_group_key
            )
            
            # 3. ì—°ë ¹ë³„ ì²´ì¸ìœ¼ë¡œ ìƒì„±
            chain = self.text_chains.get(age_group_key)
            if not chain:
                raise ValueError(f"ì—°ë ¹ë³„ ì²´ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {age_group_key}")
                
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            if progress_callback:
                await progress_callback({
                    "step": "story_generation",
                    "status": "processing",
                    "chain_type": age_group_key
                })
            
            # 4. í…ìŠ¤íŠ¸ ìƒì„± with ì²´ì¸ ì˜¤ë¸Œ ì†ŒíŠ¸
            logger.info(f"ğŸ”¥ í…ìŠ¤íŠ¸ ìƒì„± ì‹œì‘ - Chain: {age_group_key}")
            logger.info(f"ğŸ”¥ Prompt ë°ì´í„° keys: {list(prompt_data.keys())}")
            
            generated_text = await chain.ainvoke(prompt_data)
            
            logger.info(f"ğŸ”¥ ìƒì„±ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(generated_text) if generated_text else 0}")
            logger.info(f"ğŸ”¥ ìƒì„±ëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {generated_text[:200] if generated_text else 'None'}...")
            
            # 5. Enhanced íŒŒì‹±
            story_data = self._parse_enhanced_story(generated_text)
            logger.info(f"ğŸ”¥ íŒŒì‹±ëœ ìŠ¤í† ë¦¬ ë°ì´í„° keys: {list(story_data.keys()) if story_data else 'None'}")
            logger.info(f"ğŸ”¥ íŒŒì‹±ëœ chapters ê°œìˆ˜: {len(story_data.get('chapters', [])) if story_data else 0}")
            
            # 6. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            generation_time = time.time() - start_time
            self._update_performance_metrics(generation_time, True, age_group_key)
            
            # 7. ìµœì¢… ê²°ê³¼ êµ¬ì„±
            result = {
                "story_id": story_id,
                "title": story_data.get("title", "ìƒì„±ëœ ë™í™”"),
                "chapters": story_data.get("chapters", []),
                "metadata": {
                    "generation_time": generation_time,
                    "model_used": self.model_name,
                    "age_group": age_group_key,
                    "rag_sources": [story.get("title", "Unknown") for story in reference_stories],
                    "reasoning_process": story_data.get("reasoning_process", ""),
                    "prompt_version": "2.0_enhanced",
                    "educational_integration": story_data.get("educational_integration", ""),
                    "chain_of_thought": True
                }
            }
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            if progress_callback:
                await progress_callback({
                    "step": "enhanced_text_generation",
                    "status": "completed",
                    "story_id": story_id,
                    "generation_time": generation_time,
                    "chapters_count": len(story_data.get("chapters", []))
                })
            
            return result
            
        except Exception as e:
            self._update_performance_metrics(0, False, age_group_key if 'age_group_key' in locals() else "unknown")
            logger.error(f"Enhanced í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    async def _retrieve_similar_stories(self, input_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ChromaDBì—ì„œ ìœ ì‚¬ ìŠ¤í† ë¦¬ ê²€ìƒ‰ (Enhanced)"""
        if not self.vector_store:
            logger.warning("VectorDBê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ. RAG ê²€ìƒ‰ ìƒëµ")
            return []
        
        try:
            # ì¿¼ë¦¬ êµ¬ì„± (ë” ì •êµí•œ ê²€ìƒ‰)
            theme = input_data.get("theme", "")
            educational_value = input_data.get("educational_value", "")
            interests = input_data.get("interests", [])
            age_group = input_data.get("target_age", input_data.get("age_group", 7))
            
            query_text = f"{theme} {educational_value} {' '.join(interests)}"
            
            # ì—°ë ¹ëŒ€ì— ë”°ë¥¸ í•„í„°ë§
            metadata_filter = {
                "age_min": {"$lte": age_group},
                "age_max": {"$gte": age_group}
            } if isinstance(age_group, int) else {}
            
            # ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰ (get_similar_stories ì‚¬ìš©)
            # get_similar_storiesëŠ” ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ asyncio.to_thread ì‚¬ìš©
            results = await asyncio.to_thread(
                get_similar_stories,
                vector_db=self.vector_store,
                query_text=query_text,
                n_results=5,
                metadata_filter=metadata_filter,
                collection_name=self.collection_name,
                doc_type="summary" # í•„ìš”ì‹œ ë‹¤ë¥¸ doc_type ì§€ì • ê°€ëŠ¥
            )
            
            logger.info(f"RAG ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œì˜ ìœ ì‚¬ ìŠ¤í† ë¦¬ ë°˜í™˜")
            return results
            
        except Exception as e:
            logger.warning(f"Enhanced RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}. ë¹ˆ ì°¸ê³  ìŠ¤í† ë¦¬ ë°˜í™˜")
            return []

    def _prepare_enhanced_prompt_data(self, input_data: Dict[str, Any], 
                                    reference_stories: List[Dict[str, Any]], 
                                    age_group: str) -> Dict[str, Any]:
        """Enhanced í”„ë¡¬í”„íŠ¸ ë°ì´í„° ì¤€ë¹„"""
        
        # ê¸°ë³¸ ìŠ¤í† ë¦¬ ì •ë³´
        story_outline = {
            "theme": input_data.get("theme", ""),
            "plot_summary": input_data.get("plot_summary", ""),
            "educational_value": input_data.get("educational_value", ""),
            "target_age": input_data.get("target_age", 7),
            "setting": input_data.get("setting", ""),
            "characters": input_data.get("characters", [])
        }
        
        # ì•„ì´ ì •ë³´
        child_info = {
            "name": input_data.get("child_name", "ì¹œêµ¬"),
            "age": input_data.get("target_age", 7),
            "interests": input_data.get("interests", []),
            "learning_preferences": input_data.get("learning_preferences", [])
        }
        
        # ì°¸ê³  ìŠ¤í† ë¦¬ í¬ë§·íŒ… (ë” ì •êµí•œ êµ¬ì¡°)
        formatted_references = []
        for story in reference_stories[:3]:  # ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©
            formatted_references.append({
                "title": story.get("title", ""),
                "summary": story.get("content", "")[:300] + "...",
                "educational_theme": story.get("educational_theme", ""),
                "age_group": story.get("age_group", ""),
                "key_lessons": story.get("key_lessons", [])
            })
        
        return {
            "story_outline": json.dumps(story_outline, ensure_ascii=False, indent=2),
            "reference_stories": json.dumps(formatted_references, ensure_ascii=False, indent=2),
            "child_info": json.dumps(child_info, ensure_ascii=False, indent=2)
        }
    
    def _parse_enhanced_story(self, generated_text: str) -> Dict[str, Any]:
        """Enhanced ìŠ¤í† ë¦¬ íŒŒì‹± (JSON í˜•ì‹ ì§€ì› + ì¶”ë¡  ê³¼ì • ì¶”ì¶œ)"""
        try:
            # JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
            json_match = re.search(r'```json\s*(.*?)\s*```', generated_text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(1)
                parsed_data = json.loads(json_str)
                
                # ì¶”ë¡  ê³¼ì •ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                if "reasoning_process" not in parsed_data:
                    # í…ìŠ¤íŠ¸ì—ì„œ ì¶”ë¡  ê³¼ì • ì¶”ì¶œ ì‹œë„
                    reasoning_match = re.search(r'ì¶”ë¡ \s*ê³¼ì •[:\s]*(.*?)(?=\n\n|\n#|$)', generated_text, re.DOTALL | re.IGNORECASE)
                    if reasoning_match:
                        parsed_data["reasoning_process"] = reasoning_match.group(1).strip()
                
                return parsed_data
            else:
                # JSON ë¸”ë¡ì´ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ íŒŒì‹±
                return self._parse_text_story_enhanced(generated_text)
                
        except json.JSONDecodeError as e:
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, Enhanced í…ìŠ¤íŠ¸ íŒŒì‹±ìœ¼ë¡œ ì „í™˜: {e}")
            return self._parse_text_story_enhanced(generated_text)
    
    def _parse_text_story_enhanced(self, text: str) -> Dict[str, Any]:
        """Enhanced í…ìŠ¤íŠ¸ ìŠ¤í† ë¦¬ íŒŒì‹±"""
        try:
            # ê¸°ë³¸ ì œëª© ì¶”ì¶œ
            title_match = re.search(r'ì œëª©[:\s]*(.*?)(?=\n|$)', text, re.IGNORECASE)
            title = title_match.group(1).strip() if title_match else "ìƒì„±ëœ ë™í™”"
            
            # ì±•í„° ì¶”ì¶œ (ë” ì •êµí•œ íŒ¨í„´)
            chapter_patterns = [
                r'ì±•í„°\s*(\d+)[:\s]*(.*?)(?=ì±•í„°\s*\d+|$)',
                r'ì¥\s*(\d+)[:\s]*(.*?)(?=ì¥\s*\d+|$)',
                r'(\d+)\.\s*(.*?)(?=\d+\.|$)'
            ]
            
            chapters = []
            for pattern in chapter_patterns:
                matches = re.finditer(pattern, text, re.DOTALL | re.IGNORECASE)
                if matches:
                    for match in matches:
                        chapter_num = int(match.group(1))
                        chapter_content = match.group(2).strip()
                        
                        # ì±•í„° ì œëª©ê³¼ ë‚´ìš© ë¶„ë¦¬
                        lines = chapter_content.split('\n', 1)
                        chapter_title = lines[0].strip()
                        chapter_text = lines[1].strip() if len(lines) > 1 else chapter_content
                        
                        chapters.append({
                            "chapter_number": chapter_num,
                            "chapter_title": chapter_title,
                            "chapter_content": chapter_text,
                            "educational_point": self._extract_educational_point(chapter_text),
                            "interaction_question": self._extract_interaction_question(chapter_text)
                        })
                    break
            
            # ì¶”ë¡  ê³¼ì • ì¶”ì¶œ
            reasoning_match = re.search(r'ì¶”ë¡ \s*ê³¼ì •[:\s]*(.*?)(?=\n\n|\n#|$)', text, re.DOTALL | re.IGNORECASE)
            reasoning_process = reasoning_match.group(1).strip() if reasoning_match else ""
            
            return {
                "title": title,
                "chapters": chapters if chapters else [{"chapter_number": 1, "chapter_title": "ë™í™”", "chapter_content": text}],
                "reasoning_process": reasoning_process
            }
            
        except Exception as e:
            logger.error(f"Enhanced í…ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {
                "title": "ìƒì„±ëœ ë™í™”",
                "chapters": [{"chapter_number": 1, "chapter_title": "ë™í™”", "chapter_content": text}],
                "reasoning_process": ""
            }
    
    def _extract_educational_point(self, text: str) -> str:
        """êµìœ¡ì  í¬ì¸íŠ¸ ì¶”ì¶œ"""
        educational_patterns = [
            r'êµìœ¡[ì ì¸]*\s*[í¬ì¸íŠ¸|ë‚´ìš©|ê°€ì¹˜][:\s]*(.*?)(?=\n|$)',
            r'ë°°ìš¸\s*ì [:\s]*(.*?)(?=\n|$)',
            r'êµí›ˆ[:\s]*(.*?)(?=\n|$)'
        ]
        
        for pattern in educational_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return ""
    
    def _extract_interaction_question(self, text: str) -> str:
        """ìƒí˜¸ì‘ìš© ì§ˆë¬¸ ì¶”ì¶œ"""
        question_patterns = [
            r'ì§ˆë¬¸[:\s]*(.*?\?)',
            r'(.*?ëŠ”\s*ì–´ë–»ê²Œ\s*ìƒê°í•˜ë‚˜ìš”\?)',
            r'(.*?ë¼ë©´\s*ì–´ë–»ê²Œ\s*í• ê¹Œìš”\?)'
        ]
        
        for pattern in question_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return ""
    
    def _update_performance_metrics(self, generation_time: float, success: bool, age_group: str):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ (Enhanced)"""
        if not self.enable_performance_tracking:
            return
            
        if success:
            self.performance_metrics["generation_times"].append(generation_time)
            
            # ì—°ë ¹ëŒ€ë³„ ì‚¬ìš©ëŸ‰ ì¶”ì 
            if age_group not in self.performance_metrics["age_group_usage"]:
                self.performance_metrics["age_group_usage"][age_group] = 0
            self.performance_metrics["age_group_usage"][age_group] += 1
            
            # ì„±ê³µë¥  ê³„ì‚°
            total_attempts = len(self.performance_metrics["generation_times"]) + self.performance_metrics["error_count"]
            self.performance_metrics["success_rate"] = len(self.performance_metrics["generation_times"]) / total_attempts
        else:
            self.performance_metrics["error_count"] += 1
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ (Enhanced)"""
        if not self.performance_metrics["generation_times"]:
            return self.performance_metrics
            
        times = self.performance_metrics["generation_times"]
        return {
            **self.performance_metrics,
            "avg_generation_time": sum(times) / len(times),
            "min_generation_time": min(times),
            "max_generation_time": max(times),
            "total_generations": len(times),
            "most_used_age_group": max(self.performance_metrics["age_group_usage"], 
                                     key=self.performance_metrics["age_group_usage"].get, 
                                     default="unknown") if self.performance_metrics["age_group_usage"] else "unknown"
        }
    
    async def health_check(self) -> Dict[str, bool]:
        """Enhanced ìƒíƒœ í™•ì¸"""
        health_status = {
            "enhanced_prompts_loaded": bool(self.prompts),
            "vector_db_connected": bool(self.vector_store),
            "age_4_7_chain_ready": "age_4_7" in self.text_chains,
            "age_8_9_chain_ready": "age_8_9" in self.text_chains,
            "performance_tracking": self.enable_performance_tracking
        }
        
        # ì „ì²´ ìƒíƒœ
        health_status["overall_healthy"] = all(health_status.values())
        
        return health_status 